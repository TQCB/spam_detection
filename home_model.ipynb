{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML/DL\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "\n",
    "# Technical\n",
    "import os\n",
    "import time\n",
    "import typing\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jurong point , crazy .. available bugis n grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar ... joke wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun early hor ... u c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah I think usf , live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  jurong point , crazy .. available bugis n grea...\n",
       "1      0                      ok lar ... joke wif u oni ...\n",
       "2      1  free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3      0                        u dun early hor ... u c ...\n",
       "4      0                             nah I think usf , live"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'data\\data_clean.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 5_000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "def tokenize(text, tokenizer, num_words):\n",
    "    tokenizer = tokenizer(num_words=num_words, oov_token='oov')\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    return tokenizer.texts_to_sequences(text)\n",
    "\n",
    "df['token'] = tokenize(df['text'], k.preprocessing.text.Tokenizer, NUM_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = k.preprocessing.sequence.pad_sequences(df['token'], maxlen=None, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3639    1  370 ...    0    0    0]\n",
      " [ 101  183 1168 ...    0    0    0]\n",
      " [4885  364    3 ...    0    0    0]\n",
      " ...\n",
      " [  33 1657  323 ...    0    0    0]\n",
      " [2777   12   73 ...    0    0    0]\n",
      " [   2   19  382 ...    0    0    0]], shape=(64, 78), dtype=int32) tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0], shape=(64,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(padded, df['label'], test_size=0.2)\n",
    "train, val = tf.data.Dataset.from_tensor_slices((x_train, y_train)), tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "train_batch, val_batch = train.shuffle(len(train)).batch(BATCH_SIZE), val.shuffle(len(val)).batch(BATCH_SIZE)\n",
    "\n",
    "for text, label in train_batch.take(1):\n",
    "    print(text, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as l\n",
    "\n",
    "vocab_size = NUM_WORDS\n",
    "model = k.Sequential([\n",
    "    l.Embedding(vocab_size, 8, input_shape=[padded.shape[1],]),\n",
    "    l.GlobalAveragePooling1D(),\n",
    "    l.Dense(8, activation='swish'),\n",
    "    l.Dropout(0.2),\n",
    "    l.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = k.optimizers.Adam(learning_rate=0.1)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=k.losses.BinaryCrossentropy(),\n",
    "    metrics=[k.metrics.BinaryAccuracy(), k.metrics.Recall(), k.metrics.Precision()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 78, 8)             40000     \n",
      "                                                                 \n",
      " global_average_pooling1d_6   (None, 8)                0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,081\n",
      "Trainable params: 40,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 2s 18ms/step - loss: 0.1906 - binary_accuracy: 0.9361 - recall_6: 0.5365 - precision_6: 0.9450 - val_loss: 0.0738 - val_binary_accuracy: 0.9794 - val_recall_6: 0.9123 - val_precision_6: 0.9512 - lr: 0.0905\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.0347 - binary_accuracy: 0.9919 - recall_6: 0.9427 - precision_6: 0.9945 - val_loss: 0.0762 - val_binary_accuracy: 0.9830 - val_recall_6: 0.9064 - val_precision_6: 0.9810 - lr: 0.0819\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0158 - binary_accuracy: 0.9966 - recall_6: 0.9826 - precision_6: 0.9912 - val_loss: 0.0792 - val_binary_accuracy: 0.9839 - val_recall_6: 0.9240 - val_precision_6: 0.9693 - lr: 0.0741\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.0084 - binary_accuracy: 0.9982 - recall_6: 0.9878 - precision_6: 0.9982 - val_loss: 0.1108 - val_binary_accuracy: 0.9839 - val_recall_6: 0.9064 - val_precision_6: 0.9873 - lr: 0.0670\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0076 - binary_accuracy: 0.9984 - recall_6: 0.9896 - precision_6: 0.9982 - val_loss: 0.1039 - val_binary_accuracy: 0.9839 - val_recall_6: 0.9181 - val_precision_6: 0.9752 - lr: 0.0607\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.0052 - binary_accuracy: 0.9991 - recall_6: 0.9931 - precision_6: 1.0000 - val_loss: 0.1679 - val_binary_accuracy: 0.9839 - val_recall_6: 0.8947 - val_precision_6: 1.0000 - lr: 0.0549\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0045 - binary_accuracy: 0.9991 - recall_6: 0.9948 - precision_6: 0.9983 - val_loss: 0.1300 - val_binary_accuracy: 0.9830 - val_recall_6: 0.9064 - val_precision_6: 0.9810 - lr: 0.0497\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.0035 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1207 - val_binary_accuracy: 0.9848 - val_recall_6: 0.9181 - val_precision_6: 0.9812 - lr: 0.0449\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.0040 - binary_accuracy: 0.9991 - recall_6: 0.9965 - precision_6: 0.9965 - val_loss: 0.2003 - val_binary_accuracy: 0.9821 - val_recall_6: 0.8830 - val_precision_6: 1.0000 - lr: 0.0407\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.0039 - binary_accuracy: 0.9993 - recall_6: 0.9948 - precision_6: 1.0000 - val_loss: 0.1582 - val_binary_accuracy: 0.9839 - val_recall_6: 0.9006 - val_precision_6: 0.9935 - lr: 0.0368\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0037 - binary_accuracy: 0.9987 - recall_6: 0.9931 - precision_6: 0.9965 - val_loss: 0.1909 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8713 - val_precision_6: 1.0000 - lr: 0.0333\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.0045 - binary_accuracy: 0.9993 - recall_6: 0.9965 - precision_6: 0.9983 - val_loss: 0.1496 - val_binary_accuracy: 0.9830 - val_recall_6: 0.8947 - val_precision_6: 0.9935 - lr: 0.0301\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1304 - val_binary_accuracy: 0.9812 - val_recall_6: 0.9123 - val_precision_6: 0.9630 - lr: 0.0273\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0030 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1545 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8830 - val_precision_6: 0.9934 - lr: 0.0247\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0027 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1897 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8772 - val_precision_6: 1.0000 - lr: 0.0223\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1335 - val_binary_accuracy: 0.9803 - val_recall_6: 0.9181 - val_precision_6: 0.9515 - lr: 0.0202\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0018 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1509 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8947 - val_precision_6: 0.9745 - lr: 0.0183\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.0030 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1687 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8830 - val_precision_6: 0.9934 - lr: 0.0165\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0015 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1484 - val_binary_accuracy: 0.9812 - val_recall_6: 0.9006 - val_precision_6: 0.9747 - lr: 0.0150\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0026 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1636 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8830 - val_precision_6: 0.9934 - lr: 0.0135\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0029 - binary_accuracy: 0.9991 - recall_6: 0.9965 - precision_6: 0.9965 - val_loss: 0.2083 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8655 - val_precision_6: 1.0000 - lr: 0.0122\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1520 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8889 - val_precision_6: 0.9870 - lr: 0.0111\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.0032 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1386 - val_binary_accuracy: 0.9821 - val_recall_6: 0.9123 - val_precision_6: 0.9689 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0024 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1980 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8772 - val_precision_6: 1.0000 - lr: 0.0091\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0021 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1548 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 0.0082\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0013 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1836 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8772 - val_precision_6: 1.0000 - lr: 0.0074\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0029 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1754 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8772 - val_precision_6: 0.9934 - lr: 0.0067\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.0022 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1474 - val_binary_accuracy: 0.9812 - val_recall_6: 0.9064 - val_precision_6: 0.9688 - lr: 0.0061\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0023 - binary_accuracy: 0.9993 - recall_6: 0.9983 - precision_6: 0.9965 - val_loss: 0.1503 - val_binary_accuracy: 0.9812 - val_recall_6: 0.9006 - val_precision_6: 0.9747 - lr: 0.0055\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.0026 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1645 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8889 - val_precision_6: 0.9870 - lr: 0.0050\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0028 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1486 - val_binary_accuracy: 0.9803 - val_recall_6: 0.9006 - val_precision_6: 0.9686 - lr: 0.0045\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.0020 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1564 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 0.0041\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0025 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1516 - val_binary_accuracy: 0.9812 - val_recall_6: 0.9006 - val_precision_6: 0.9747 - lr: 0.0037\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0027 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1619 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8889 - val_precision_6: 0.9870 - lr: 0.0033\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1576 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 0.0030\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1518 - val_binary_accuracy: 0.9803 - val_recall_6: 0.9006 - val_precision_6: 0.9686 - lr: 0.0027\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1644 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8889 - val_precision_6: 0.9870 - lr: 0.0025\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0029 - binary_accuracy: 0.9993 - recall_6: 0.9983 - precision_6: 0.9965 - val_loss: 0.1691 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8830 - val_precision_6: 0.9869 - lr: 0.0022\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1652 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8889 - val_precision_6: 0.9870 - lr: 0.0020\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1605 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 0.0018\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1568 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 0.0017\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1577 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 0.0015\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0020 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1613 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 0.0014\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0024 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1582 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 0.0012\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0015 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1640 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8889 - val_precision_6: 0.9870 - lr: 0.0011\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0018 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1643 - val_binary_accuracy: 0.9812 - val_recall_6: 0.8889 - val_precision_6: 0.9870 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0022 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1622 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 9.0953e-04\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1605 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 8.2297e-04\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1618 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 7.4466e-04\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0022 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1592 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8889 - val_precision_6: 0.9744 - lr: 6.7379e-04\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.0016 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1612 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 6.0967e-04\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1604 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 5.5166e-04\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0020 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1613 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 4.9916e-04\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0022 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1612 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 4.5166e-04\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.0020 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1613 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 4.0868e-04\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.0018 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1625 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 3.6979e-04\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0017 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1635 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 3.3460e-04\n",
      "Epoch 58/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1620 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 3.0276e-04\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0023 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1618 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 2.7394e-04\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1614 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 2.4788e-04\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0018 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1619 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 2.2429e-04\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0018 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1625 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 2.0294e-04\n",
      "Epoch 63/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0016 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1629 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.8363e-04\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0022 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1633 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.6616e-04\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0018 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1631 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.5034e-04\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0020 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1632 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.3604e-04\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0023 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1629 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.2309e-04\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1633 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.1138e-04\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1623 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.0078e-04\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0018 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1625 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 9.1188e-05\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0022 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1621 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 8.2511e-05\n",
      "Epoch 72/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0023 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1623 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 7.4659e-05\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.0020 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1626 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 6.7554e-05\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1624 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 6.1125e-05\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0023 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1622 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 5.5308e-05\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0020 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1622 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8889 - val_precision_6: 0.9744 - lr: 5.0045e-05\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0021 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1622 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8889 - val_precision_6: 0.9744 - lr: 4.5283e-05\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0025 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1622 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8889 - val_precision_6: 0.9744 - lr: 4.0974e-05\n",
      "Epoch 79/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0023 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1621 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8889 - val_precision_6: 0.9744 - lr: 3.7074e-05\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0017 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1621 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8889 - val_precision_6: 0.9744 - lr: 3.3546e-05\n",
      "Epoch 81/100\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.0016 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1622 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8889 - val_precision_6: 0.9744 - lr: 3.0354e-05\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.0012 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1623 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8889 - val_precision_6: 0.9744 - lr: 2.7465e-05\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0015 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1624 - val_binary_accuracy: 0.9794 - val_recall_6: 0.8889 - val_precision_6: 0.9744 - lr: 2.4852e-05\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0018 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1626 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 2.2487e-05\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1626 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 2.0347e-05\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.0022 - binary_accuracy: 0.9993 - recall_6: 0.9983 - precision_6: 0.9965 - val_loss: 0.1626 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.8411e-05\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.6659e-05\n",
      "Epoch 88/100\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.0017 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1628 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.5073e-05\n",
      "Epoch 89/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0025 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.3639e-05\n",
      "Epoch 90/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.2341e-05\n",
      "Epoch 91/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0024 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.1167e-05\n",
      "Epoch 92/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0023 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 1.0104e-05\n",
      "Epoch 93/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0023 - binary_accuracy: 0.9996 - recall_6: 0.9983 - precision_6: 0.9983 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 9.1424e-06\n",
      "Epoch 94/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 8.2724e-06\n",
      "Epoch 95/100\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 7.4852e-06\n",
      "Epoch 96/100\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 6.7729e-06\n",
      "Epoch 97/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 6.1284e-06\n",
      "Epoch 98/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 5.5452e-06\n",
      "Epoch 99/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.0020 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 5.0175e-06\n",
      "Epoch 100/100\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.0022 - binary_accuracy: 0.9998 - recall_6: 0.9983 - precision_6: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 0.9803 - val_recall_6: 0.8889 - val_precision_6: 0.9806 - lr: 4.5400e-06\n"
     ]
    }
   ],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    lr = lr * np.exp(-0.1)\n",
    "    return lr\n",
    "cp_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "hist = model.fit(\n",
    "    train_batch,\n",
    "    validation_data=val_batch,\n",
    "    epochs=100,\n",
    "    callbacks=[cp_lr]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1627 - binary_accuracy: 0.9803 - recall_6: 0.8889 - precision_6: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16267839074134827,\n",
       " 0.9802690744400024,\n",
       " 0.8888888955116272,\n",
       " 0.9806451797485352]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a very basic model (8,000 embedding params [1000 vocab, 8 dim] and 81 layer params) we get very satisfying results.\n",
    "\n",
    "Reminder:  \n",
    "accuracy TP + TN / TP+TN+FP+FN (% of correct predictions)  \n",
    "recall TP / TP + FN (% of positive values that were correctly predicted)  \n",
    "precision TP / TP + FP (% of positive predictions that were correct)\n",
    "\n",
    "We can detect 88% of all spam cases, and 98% of our predictions are correct.\n",
    "\n",
    "Let's try seeing if using transfer learning of a more complex model can improve our performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
